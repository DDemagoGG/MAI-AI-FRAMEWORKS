{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5692fde",
   "metadata": {},
   "source": [
    "# Лабораторная работа №4 \"Проведение исследований со случайным лесом\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d807b2",
   "metadata": {},
   "source": [
    "### Ход работы"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86707da",
   "metadata": {},
   "source": [
    "Импортируем библиотеки перед работой"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7b5560c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV, train_test_split, KFold, RandomizedSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor, HistGradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from scipy.stats import randint\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from scipy.special import softmax\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2df7e8",
   "metadata": {},
   "source": [
    "##### Создание бейзлайна для модели классификации"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c036e079",
   "metadata": {},
   "source": [
    "Проведём те же манипуляции, что и ранне: выгрузим датасет и минимально его обработаем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df92cf5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_base_df = pd.read_csv(\"../classification.csv\").sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "c_base_df = c_base_df.drop(columns=['instance_id', 'obtained_date', 'track_name', 'artist_name'])\n",
    "\n",
    "c_base_df.drop_duplicates()\n",
    "\n",
    "c_base_df['tempo'] = pd.to_numeric(c_base_df['tempo'], errors='coerce')\n",
    "\n",
    "le = LabelEncoder()\n",
    "c_base_df['mode'] = le.fit_transform(c_base_df['mode'])\n",
    "c_base_df['music_genre'] = le.fit_transform(c_base_df['music_genre'])\n",
    "c_base_df['key'] = le.fit_transform(c_base_df['key'])\n",
    "\n",
    "median_tempo = c_base_df['tempo'].median()\n",
    "c_base_df['tempo'] = c_base_df['tempo'].fillna(median_tempo)\n",
    "\n",
    "X_c_base = c_base_df.drop(columns=[\"music_genre\"])\n",
    "y_c_base = c_base_df[\"music_genre\"]\n",
    "\n",
    "X_c_base_train, X_c_base_test, y_c_base_train, y_c_base_test = train_test_split(\n",
    "    X_c_base,\n",
    "    y_c_base,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y_c_base\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32aff0d",
   "metadata": {},
   "source": [
    "Теперь обучим модель из sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c7bc06d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5455\n"
     ]
    }
   ],
   "source": [
    "gb = GradientBoostingClassifier(\n",
    "    n_estimators=20,\n",
    "    learning_rate=0.8,\n",
    "    max_depth=1,\n",
    "    min_samples_split=50,\n",
    "    subsample=0.6,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "gb.fit(X_c_base_train, y_c_base_train)\n",
    "y_pred = gb.predict(X_c_base_test)\n",
    "\n",
    "accuracy = accuracy_score(y_c_base_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cba6968",
   "metadata": {},
   "source": [
    "##### Улучшение бейзлайна для модели классификации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4379a1cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.34      0.38      1000\n",
      "           1       0.72      0.68      0.70      1000\n",
      "           2       0.55      0.49      0.52      1000\n",
      "           3       0.82      0.76      0.79      1000\n",
      "           4       0.55      0.59      0.57      1000\n",
      "           5       0.58      0.57      0.58      1000\n",
      "           6       0.45      0.45      0.45      1000\n",
      "           7       0.47      0.45      0.46      1000\n",
      "           8       0.43      0.40      0.41      1000\n",
      "           9       0.49      0.72      0.58      1000\n",
      "\n",
      "    accuracy                           0.55     10000\n",
      "   macro avg       0.55      0.55      0.54     10000\n",
      "weighted avg       0.55      0.55      0.54     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_c_base_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97f58af",
   "metadata": {},
   "source": [
    "Теперь преобразуем датасет как ранее"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9d78ec42",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_df = pd.read_csv(\"../classification.csv\").sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "c_df = c_df.drop(columns=['instance_id', 'obtained_date', 'track_name', 'artist_name'])\n",
    "\n",
    "\n",
    "sc = StandardScaler()\n",
    "scaled = sc.fit_transform(c_df[['loudness', 'acousticness', 'energy']])\n",
    "pca = PCA(n_components=2)\n",
    "c_df[['pc1', 'pc2']] = pca.fit_transform(scaled)\n",
    "c_df = c_df.drop(columns=['loudness', 'acousticness', 'energy'])\n",
    "\n",
    "c_df['tempo'] = pd.to_numeric(c_df['tempo'], errors='coerce')\n",
    "\n",
    "le = LabelEncoder()\n",
    "c_df['music_genre'] = le.fit_transform(c_df['music_genre'])\n",
    "c_df['mode'] = le.fit_transform(c_df['mode'])\n",
    "\n",
    "ohe = OneHotEncoder(sparse_output=False, drop='first')\n",
    "encoded_key = ohe.fit_transform(c_df[['key']])\n",
    "encoded_df_key = pd.DataFrame(encoded_key, columns=ohe.get_feature_names_out(['key']))\n",
    "c_df = c_df.drop(columns=['key']).reset_index(drop=True)\n",
    "c_df = pd.concat([c_df, encoded_df_key], axis=1)\n",
    "\n",
    "c_df['duration_ms'] = c_df['duration_ms'].replace(-1, np.nan)\n",
    "\n",
    "c_df['instrumental_flag'] = (c_df['instrumentalness'] > 0.05).astype(int)\n",
    "c_df = c_df.drop(columns=['instrumentalness'])\n",
    "\n",
    "c_df['undefined_tempo'] = c_df['tempo'].isna().astype(int)\n",
    "\n",
    "median_tempo = c_df['tempo'].median()\n",
    "c_df['tempo'] = c_df['tempo'].fillna(median_tempo)\n",
    "\n",
    "median_duration = c_df['duration_ms'].median()\n",
    "c_df['duration_ms'] = c_df['duration_ms'].fillna(median_duration)\n",
    "\n",
    "float_features = [\n",
    "    'popularity', 'danceability', 'duration_ms',\n",
    "    'liveness', 'speechiness', 'tempo',\n",
    "    'valence', 'pc1', 'pc2'\n",
    "]\n",
    "\n",
    "other_features = [\n",
    "    'mode', 'instrumental_flag', 'undefined_tempo'\n",
    "] + list(encoded_df_key.columns) \n",
    "\n",
    "X_c = c_df[float_features + other_features]\n",
    "y_c = c_df['music_genre']\n",
    "\n",
    "X_c_train, X_c_test, y_c_train, y_c_test = train_test_split(\n",
    "    X_c, y_c, test_size=0.2, stratify=y_c, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c92695",
   "metadata": {},
   "source": [
    "Перейдём к обучению"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b429b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "Best params: {'learning_rate': 0.1, 'max_depth': 3, 'max_iter': 200, 'min_samples_leaf': 50}\n",
      "Score: 0.5813\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.37      0.41      1000\n",
      "           1       0.78      0.74      0.76      1000\n",
      "           2       0.61      0.51      0.56      1000\n",
      "           3       0.84      0.83      0.84      1000\n",
      "           4       0.58      0.59      0.59      1000\n",
      "           5       0.65      0.62      0.63      1000\n",
      "           6       0.44      0.49      0.46      1000\n",
      "           7       0.55      0.52      0.53      1000\n",
      "           8       0.43      0.41      0.42      1000\n",
      "           9       0.51      0.73      0.60      1000\n",
      "\n",
      "    accuracy                           0.58     10000\n",
      "   macro avg       0.59      0.58      0.58     10000\n",
      "weighted avg       0.59      0.58      0.58     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gb = HistGradientBoostingClassifier(\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "param_grid = {\n",
    "    \"max_iter\": [100, 200],\n",
    "    \"learning_rate\": [0.05, 0.1],\n",
    "    \"max_depth\": [3, 4],\n",
    "    \"min_samples_leaf\": [20, 50]\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(\n",
    "    n_splits=5,\n",
    "    shuffle=True,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    estimator=gb,\n",
    "    param_grid=param_grid,\n",
    "    scoring=\"f1_macro\",\n",
    "    cv=cv,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid.fit(X_c_train, y_c_train)\n",
    "\n",
    "print(\"Best params:\", grid.best_params_)\n",
    "\n",
    "\n",
    "best_gb = grid.best_estimator_\n",
    "\n",
    "y_pred = best_gb.predict(X_c_test)\n",
    "\n",
    "print(\"Score:\", accuracy_score(y_c_test, y_pred))\n",
    "\n",
    "print(classification_report(y_c_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e468beca",
   "metadata": {},
   "source": [
    "##### Создание бейзлайна для модели регрессии"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3a0e0e",
   "metadata": {},
   "source": [
    "Сделаем всё то же, что и ранее"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "966e03e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_base_df = pd.read_csv(\"../regression.csv\").sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "r_base_df['Date'] = pd.to_datetime(r_base_df['Date'], dayfirst=True)\n",
    "\n",
    "r_base_df[\"Year\"] = r_base_df[\"Date\"].dt.year\n",
    "r_base_df[\"Month\"] = r_base_df[\"Date\"].dt.month\n",
    "r_base_df[\"Day\"] = r_base_df[\"Date\"].dt.day\n",
    "\n",
    "r_base_df = r_base_df.drop(columns=['Date'])\n",
    "\n",
    "per_store_count = r_base_df.groupby('Store').size().iloc[0]\n",
    "k = max(1, int(np.round(0.8 * per_store_count))) \n",
    "store_counts = r_base_df['Store'].nunique()\n",
    "\n",
    "train = r_base_df.iloc[: store_counts * k]\n",
    "test = r_base_df.iloc[store_counts * k :]\n",
    "\n",
    "X_r_base_train = train.drop(columns=['Weekly_Sales'])\n",
    "X_r_base_test = test.drop(columns=['Weekly_Sales'])\n",
    "y_r_base_train = train['Weekly_Sales']\n",
    "y_r_base_test = test['Weekly_Sales']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43bc9f1a",
   "metadata": {},
   "source": [
    "И теперь обучим модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90ad067f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 179590.59773806954\n",
      "RMSE: 232642.85236654413\n",
      "R2: 0.832710565668755\n"
     ]
    }
   ],
   "source": [
    "gbr_bad = GradientBoostingRegressor(\n",
    "    n_estimators=50,    \n",
    "    learning_rate=0.3,    \n",
    "    max_depth=2,           \n",
    "    subsample=0.6,      \n",
    "    min_samples_leaf=20,   \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "gbr_bad.fit(X_r_base_train, y_r_base_train)\n",
    "\n",
    "y_pred = gbr_bad.predict(X_r_base_test)\n",
    "\n",
    "mae = mean_absolute_error(y_r_base_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_r_base_test, y_pred))\n",
    "r2 = r2_score(y_r_base_test, y_pred)\n",
    "\n",
    "print(\"MAE:\", mae)\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"R2:\", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d70f1fa",
   "metadata": {},
   "source": [
    "##### Улучшение бейзлайна для модели регрессии"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86591d1f",
   "metadata": {},
   "source": [
    "Сначала повторим техники из предыдущей ЛР"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "91496706",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_df = pd.read_csv(\"../regression.csv\").sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "r_df['Date'] = pd.to_datetime(r_df['Date'], dayfirst=True)\n",
    "\n",
    "r_df['Year'] = r_df['Date'].dt.year\n",
    "r_df['Week'] = r_df['Date'].dt.isocalendar().week\n",
    "\n",
    "r_df = r_df.drop(columns=['Date'])\n",
    "\n",
    "cat_store = ['Store', 'Week']\n",
    "other_feats = ['Temperature', 'Fuel_Price', 'CPI', 'Unemployment', 'Year', 'Holiday_Flag']\n",
    "\n",
    "per_store_count = r_df.groupby('Store').size().iloc[0]\n",
    "k = max(1, int(np.round(0.8 * per_store_count))) \n",
    "store_counts = r_df['Store'].nunique()\n",
    "\n",
    "train = r_df.iloc[: store_counts * k]\n",
    "test = r_df.iloc[store_counts * k :]\n",
    "\n",
    "X_r_train = train.drop(columns=['Weekly_Sales'])\n",
    "X_r_test = test.drop(columns=['Weekly_Sales'])\n",
    "y_r_train = train['Weekly_Sales']\n",
    "y_r_test = test['Weekly_Sales']\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('ohe', OneHotEncoder(handle_unknown='ignore', sparse_output=False), cat_store),\n",
    "        ('passth', 'passthrough', other_feats)\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc67618",
   "metadata": {},
   "source": [
    "Перейдём к обучению"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacb2c92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n",
      "Best params: {'model__learning_rate': 0.1, 'model__max_depth': 4, 'model__min_samples_leaf': 20, 'model__n_estimators': 300, 'model__subsample': 1.0}\n",
      "MAE: 66673.26203114892\n",
      "RMSE: 107858.98478310673\n",
      "R2: 0.9640414855804225\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"model\", GradientBoostingRegressor(random_state=42))\n",
    "    ]\n",
    ")\n",
    "\n",
    "param_grid = {\n",
    "    \"model__n_estimators\": [200, 300],\n",
    "    \"model__learning_rate\": [0.05, 0.1],\n",
    "    \"model__max_depth\": [3, 4],\n",
    "    \"model__subsample\": [0.8, 1.0],\n",
    "    \"model__min_samples_leaf\": [5, 20]\n",
    "}\n",
    "\n",
    "cv = KFold(\n",
    "    n_splits=5,\n",
    "    shuffle=True,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    estimator=pipe,\n",
    "    param_grid=param_grid,\n",
    "    scoring=\"neg_root_mean_squared_error\",\n",
    "    cv=cv,\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "grid.fit(X_r_train, y_r_train)\n",
    "\n",
    "print(\"Best params:\", grid.best_params_)\n",
    "best_model = grid.best_estimator_\n",
    "y_test_pred  = best_model.predict(X_r_test)\n",
    "\n",
    "mae = mean_absolute_error(y_r_test, y_test_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_r_test, y_test_pred))\n",
    "r2 = r2_score(y_r_test, y_test_pred)\n",
    "\n",
    "print(\"MAE:\", mae)\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"R2:\", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad25589c",
   "metadata": {},
   "source": [
    "##### Базовый класс имплементации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242d95fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseGradientBoosting:\n",
    "\n",
    "    def __init__(self, learning_rate=0.1, max_depth=3, \n",
    "                 min_samples_leaf=1, n_estimators=100, \n",
    "                 subsample=1.0, random_state=None, min_samples_split=2):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "        self.n_estimators = n_estimators\n",
    "        self.subsample = subsample\n",
    "        self.random_state = random_state\n",
    "\n",
    "        self.trees = []  # список слабых моделей\n",
    "        self.initial_prediction = None  # начальные предсказания\n",
    "\n",
    "    def _init_prediction(self, y):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def _loss_gradient(self, y, y_pred):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def predict_raw(self, X):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def predict(self, X):\n",
    "        raise NotImplementedError\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35a7444",
   "metadata": {},
   "source": [
    "##### Классификатор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230e502b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyGradientBoostingClassifier(BaseGradientBoosting):\n",
    "    \"\"\"\n",
    "    Многоклассовый градиентный бустинг.\n",
    "    Использует softmax и кросс-энтропию.\n",
    "    \"\"\"\n",
    "\n",
    "    def _init_prediction(self, y):\n",
    "        self.classes_ = np.unique(y)\n",
    "        n_classes = len(self.classes_)\n",
    "        counts = np.array([np.sum(y == c) for c in self.classes_], dtype=np.float32)\n",
    "        probs = counts / counts.sum()\n",
    "        init_pred = np.log(np.clip(probs, 1e-6, 1-1e-6)) \n",
    "        return init_pred\n",
    "    \n",
    "    def _loss_gradient(self, y, y_pred):\n",
    "        \"\"\"\n",
    "        Градиент кросс-энтропии:\n",
    "        gradient = y_one_hot - softmax(y_pred)\n",
    "        \"\"\"\n",
    "        n_samples = y.shape[0]\n",
    "        n_classes = len(self.classes_)\n",
    "        # one-hot encoding\n",
    "        y_one_hot = np.zeros((n_samples, n_classes), dtype=np.float32)\n",
    "        for idx, c in enumerate(self.classes_):\n",
    "            y_one_hot[:, idx] = (y == c).astype(np.float32)\n",
    "        # softmax по строкам\n",
    "        p = softmax(y_pred, axis=1)\n",
    "        grad = y_one_hot - p\n",
    "        return grad\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Обучение многоклассового градиентного бустинга\n",
    "        \"\"\"\n",
    "        X = np.asarray(X)\n",
    "        y = np.asarray(y)\n",
    "        n_samples = X.shape[0]\n",
    "        n_classes = len(np.unique(y))\n",
    "\n",
    "        # Начальное предсказание (логиты)\n",
    "        self.initial_prediction = self._init_prediction(y)\n",
    "        y_pred = np.tile(self.initial_prediction, (n_samples, 1))  \n",
    "\n",
    "        self.trees = [[] for _ in range(n_classes)] \n",
    "        rng = np.random.default_rng(self.random_state)\n",
    "\n",
    "        for i in range(self.n_estimators):\n",
    "            # Вычисляем градиенты для каждого класса\n",
    "            gradient = self._loss_gradient(y, y_pred) \n",
    "\n",
    "            for k in range(n_classes):\n",
    "                # Подвыборка для дерева\n",
    "                if self.subsample < 1.0:\n",
    "                    indices = rng.choice(n_samples, int(n_samples * self.subsample), replace=False)\n",
    "                    X_sub, grad_sub = X[indices], gradient[indices, k]\n",
    "                else:\n",
    "                    X_sub, grad_sub = X, gradient[:, k]\n",
    "\n",
    "                # Обучаем дерево\n",
    "                tree = DecisionTreeRegressor(\n",
    "                    max_depth=self.max_depth,\n",
    "                    min_samples_leaf=self.min_samples_leaf,\n",
    "                    min_samples_split=self.min_samples_split,\n",
    "                    random_state=self.random_state\n",
    "                )\n",
    "                tree.fit(X_sub, grad_sub)\n",
    "\n",
    "                # Обновляем предсказание\n",
    "                update = tree.predict(X).astype(np.float32)\n",
    "                y_pred[:, k] += self.learning_rate * update\n",
    "\n",
    "                # Сохраняем дерево\n",
    "                self.trees[k].append(tree)\n",
    "\n",
    "                del X_sub, grad_sub, update\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict_raw(self, X):\n",
    "        X = np.asarray(X)\n",
    "        n_samples = X.shape[0]\n",
    "        y_pred = np.tile(self.initial_prediction, (n_samples, 1))\n",
    "\n",
    "        for k, trees_k in enumerate(self.trees):\n",
    "            for tree in trees_k:\n",
    "                y_pred[:, k] += self.learning_rate * tree.predict(X).astype(np.float32)\n",
    "        return y_pred\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"\n",
    "        Вероятности для всех классов\n",
    "        \"\"\"\n",
    "        y_raw = self.predict_raw(X)\n",
    "        return softmax(y_raw, axis=1)\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Предсказанные классы\n",
    "        \"\"\"\n",
    "        probs = self.predict_proba(X)\n",
    "        class_idx = np.argmax(probs, axis=1)\n",
    "        return self.classes_[class_idx]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493088c7",
   "metadata": {},
   "source": [
    "Обучим на данных бейзлайна"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "aa88322c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4681\n"
     ]
    }
   ],
   "source": [
    "gb = MyGradientBoostingClassifier(\n",
    "    n_estimators=20,\n",
    "    learning_rate=0.8,\n",
    "    max_depth=1,\n",
    "    min_samples_split=50,\n",
    "    subsample=0.6\n",
    ")\n",
    "\n",
    "gb.fit(X_c_base_train, y_c_base_train)\n",
    "y_pred = gb.predict(X_c_base_test)\n",
    "\n",
    "accuracy = accuracy_score(y_c_base_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4a2dd75a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.28      0.32      1000\n",
      "           1       0.59      0.62      0.61      1000\n",
      "           2       0.38      0.37      0.38      1000\n",
      "           3       0.71      0.79      0.75      1000\n",
      "           4       0.55      0.44      0.49      1000\n",
      "           5       0.44      0.40      0.42      1000\n",
      "           6       0.42      0.42      0.42      1000\n",
      "           7       0.41      0.22      0.29      1000\n",
      "           8       0.42      0.31      0.35      1000\n",
      "           9       0.39      0.83      0.53      1000\n",
      "\n",
      "    accuracy                           0.47     10000\n",
      "   macro avg       0.47      0.47      0.45     10000\n",
      "weighted avg       0.47      0.47      0.45     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_c_base_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc2e88b",
   "metadata": {},
   "source": [
    "Обучим на данных улучшенной модели. Сразу будем использовать параметры, полученные при подборе гиперпараметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d010cf26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.5431\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.34      0.37      1000\n",
      "           1       0.71      0.69      0.70      1000\n",
      "           2       0.54      0.46      0.50      1000\n",
      "           3       0.81      0.81      0.81      1000\n",
      "           4       0.54      0.50      0.52      1000\n",
      "           5       0.58      0.52      0.55      1000\n",
      "           6       0.47      0.48      0.47      1000\n",
      "           7       0.48      0.42      0.45      1000\n",
      "           8       0.45      0.45      0.45      1000\n",
      "           9       0.48      0.77      0.59      1000\n",
      "\n",
      "    accuracy                           0.54     10000\n",
      "   macro avg       0.54      0.54      0.54     10000\n",
      "weighted avg       0.54      0.54      0.54     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gb = MyGradientBoostingClassifier(\n",
    "    learning_rate=0.1,\n",
    "    max_depth=3,\n",
    "    n_estimators=200,\n",
    "    min_samples_leaf=50\n",
    ")\n",
    "\n",
    "\n",
    "gb.fit(X_c_train, y_c_train)\n",
    "\n",
    "y_pred = gb.predict(X_c_test)\n",
    "\n",
    "print(\"Score:\", accuracy_score(y_c_test, y_pred))\n",
    "\n",
    "print(classification_report(y_c_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b302f3",
   "metadata": {},
   "source": [
    "Имеем скоры:\n",
    "\n",
    "**Бейзлайн sklearn** - 0.5455\n",
    "\n",
    "**Улучшенная модель sklearn** - 0.5813\n",
    "\n",
    "**Мой бейзлайн** - 0.4681\n",
    "\n",
    "**Мой улучшенный бейзлайн** - 0.5431\n",
    "\n",
    "Моя улучшенная модель едва подбирается к бейзлайну sklearn. Но в целом получилось неплохо"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28535818",
   "metadata": {},
   "source": [
    "##### Регрессор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db4bf6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyGradientBoostingRegressor(BaseGradientBoosting):\n",
    "    \"\"\"\n",
    "    Градиентный бустинг для регрессии.\n",
    "    \"\"\"\n",
    "\n",
    "    def _init_prediction(self, y):\n",
    "        \"\"\"\n",
    "        Начальное предсказание — среднее по целевой переменной.\n",
    "        \"\"\"\n",
    "        return np.array(np.mean(y), dtype=np.float32)\n",
    "\n",
    "    def _loss_gradient(self, y, y_pred):\n",
    "        \"\"\"\n",
    "        Градиент MSE: y - y_pred\n",
    "        \"\"\"\n",
    "        return y - y_pred\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X = np.asarray(X)\n",
    "        y = np.asarray(y, dtype=np.float32)\n",
    "        n_samples = X.shape[0]\n",
    "\n",
    "        # Начальное предсказание (среднее)\n",
    "        self.initial_prediction = self._init_prediction(y)\n",
    "        y_pred = np.full(y.shape, self.initial_prediction, dtype=np.float32)\n",
    "\n",
    "        rng = np.random.default_rng(self.random_state)\n",
    "        self.trees = []\n",
    "\n",
    "        for i in range(self.n_estimators):\n",
    "            # Вычисляем градиент\n",
    "            gradient = self._loss_gradient(y, y_pred)\n",
    "\n",
    "            # Подвыборка для дерева\n",
    "            if self.subsample < 1.0:\n",
    "                indices = rng.choice(n_samples, int(n_samples * self.subsample), replace=False)\n",
    "                X_sub, grad_sub = X[indices], gradient[indices]\n",
    "            else:\n",
    "                X_sub, grad_sub = X, gradient\n",
    "\n",
    "            # Обучаем дерево\n",
    "            tree = DecisionTreeRegressor(\n",
    "                max_depth=self.max_depth,\n",
    "                min_samples_leaf=self.min_samples_leaf,\n",
    "                min_samples_split=self.min_samples_split,\n",
    "                random_state=self.random_state\n",
    "            )\n",
    "            tree.fit(X_sub, grad_sub)\n",
    "\n",
    "            # Обновляем предсказание\n",
    "            update = tree.predict(X).astype(np.float32)\n",
    "            y_pred += self.learning_rate * update\n",
    "\n",
    "            # Сохраняем дерево\n",
    "            self.trees.append(tree)\n",
    "\n",
    "            # Очистка для экономии памяти\n",
    "            del gradient, update, X_sub, grad_sub\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict_raw(self, X):\n",
    "        \"\"\"\n",
    "        Предсказание до применения каких-либо финальных функций \n",
    "        \"\"\"\n",
    "        X = np.asarray(X)\n",
    "        y_pred = np.full((X.shape[0],), self.initial_prediction, dtype=np.float32)\n",
    "        for tree in self.trees:\n",
    "            y_pred += self.learning_rate * tree.predict(X).astype(np.float32)\n",
    "        return y_pred\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.predict_raw(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b3dbeb",
   "metadata": {},
   "source": [
    "Обучим на данных бейзлайна"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f92bf2c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 181877.8959808429\n",
      "RMSE: 233175.45168499125\n",
      "R2: 0.8319437230512261\n"
     ]
    }
   ],
   "source": [
    "gbr_bad = MyGradientBoostingRegressor(\n",
    "    n_estimators=50,    \n",
    "    learning_rate=0.3,    \n",
    "    max_depth=2,           \n",
    "    subsample=0.6,      \n",
    "    min_samples_leaf=20\n",
    ")\n",
    "\n",
    "gbr_bad.fit(X_r_base_train, y_r_base_train)\n",
    "\n",
    "y_pred = gbr_bad.predict(X_r_base_test)\n",
    "\n",
    "mae = mean_absolute_error(y_r_base_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_r_base_test, y_pred))\n",
    "r2 = r2_score(y_r_base_test, y_pred)\n",
    "\n",
    "print(\"MAE:\", mae)\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"R2:\", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec45c824",
   "metadata": {},
   "source": [
    "Обучим на данных улучшенной модели. Сразу будем использовать параметры, полученные при подборе гиперпараметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e562b222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 66664.9429322318\n",
      "RMSE: 107814.45816134539\n",
      "R2: 0.9640711684239329\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"model\", MyGradientBoostingRegressor(min_samples_split=2, n_estimators=300, learning_rate=0.1, max_depth=4, min_samples_leaf=20, subsample=1))\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipe.fit(X_r_train, y_r_train)\n",
    "\n",
    "y_test_pred  = pipe.predict(X_r_test)\n",
    "\n",
    "mae = mean_absolute_error(y_r_test, y_test_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_r_test, y_test_pred))\n",
    "r2 = r2_score(y_r_test, y_test_pred)\n",
    "\n",
    "print(\"MAE:\", mae)\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"R2:\", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30710f48",
   "metadata": {},
   "source": [
    "Получили\n",
    "\n",
    "| Метрика | Бейзлайн бустинга | Бейзлайн имплементации | Улучшенный бустинг | Улучшенная имплементация |\n",
    "|-|-|-|-|-|\n",
    "| MAE | 179591 | 181878 | 66673 | 66665 |\n",
    "| RMSE | 232643 | 233175 | 107859 | 107814 |\n",
    "| R2 | 0.833 | 0.832 | 0.964 | 0.964 |\n",
    "\n",
    "Везде получились практически одинаковые метрики. Это успех"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
