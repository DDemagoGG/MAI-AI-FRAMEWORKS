# MAI-AI-FRAMEWORKS
Лабораторные работы по курсу "Прикладные системы и фреймворки искусственного интеллекта"

2025г

# Сводные таблицы

### Классификация

| Model | KNN | Logistic Regression | Decision Tree | Random Tree | Gradient Boosting |
|-|-|-|-|-|-|
| Sklearn | 0.5073 | 0.5282 | 0.5141 | 0.543 | 0.5813 |
| My Implementation | 0.5077 | 0.4026 | 0.5154 | 0.5437 | 0.5431 |

### Регрессия 
**MAE**
| Model | KNN | Linear Regression | Decision Tree | Random Tree | Gradient Boosting |
|-|-|-|-|-|-|
| Sklearn | 68212 | 70758 | 68922 | 63865 | 66673 |
| My Implementation | 68212 | 70854 | 100451 | 64193 | 66665 |

**RMSE**
| Model | KNN | Linear Regression | Decision Tree | Random Tree | Gradient Boosting |
|-|-|-|-|-|-|
| Sklearn | 129073 | 109901 | 132852 | 120224 | 107859 |
| My Implementation | 129073 | 109925 | 215020 | 120375 | 107814 |\

**R2**
| Model | KNN | Linear Regression | Decision Tree | Random Tree | Gradient Boosting |
|-|-|-|-|-|-|
| Sklearn | 0.949 | 0.963 | 0.945 | 0.955 | 0.964 |
| My Implementation | 0.949 | 0.963 | 0.857 | 0.955 | 0.964 |

# Выводы
В ходе работы были реализованы и обучены основные алгоритмы машинного обучения для задач классификации и регрессии, после чего их качество было сопоставлено с реализациями из библиотеки sklearn. Полученные результаты показывают, что для большинства моделей (KNN, линейная регрессия, деревья решений в классификации, а также ансамблевые методы — случайный лес и градиентный бустинг) метрики качества практически совпадают с эталонными, что свидетельствует о корректности реализованных алгоритмов и правильной логике обучения. При этом заметные отклонения наблюдаются у логистической регрессии в задаче классификации и у дерева решений в задаче регрессии, что, вероятно, связано с упрощениями или неточностями в реализации оптимизации и критериев разбиения. В целом результаты подтверждают правильность основных реализаций и демонстрируют, что ансамблевые методы менее чувствительны к возможным ошибкам базовых моделей, обеспечивая качество, сопоставимое с библиотечными решениями.

Анализ результатов моделей sklearn показывает, что для задачи классификации наилучшее качество демонстрирует градиентный бустинг, что подтверждает его способность эффективно моделировать сложные нелинейные зависимости за счёт ансамблирования слабых моделей, тогда как более простые алгоритмы, такие как KNN, логистическая регрессия и одиночные деревья решений, показывают более низкие значения метрик и уступают ансамблевым методам. В задаче регрессии наилучшие значения MAE, RMSE и коэффициента детерминации R² также достигаются ансамблевыми подходами (градиентный бустинг и случайный лес), а также линейной регрессией, что указывает на наличие как линейных, так и слабо нелинейных зависимостей в данных; при этом одиночное дерево решений и KNN демонстрируют худшее качество по сравнению с ансамблями, что подчёркивает их склонность к переобучению или чувствительность к структуре данных.