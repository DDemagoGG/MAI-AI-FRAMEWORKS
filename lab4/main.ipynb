{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d88e6b6",
   "metadata": {},
   "source": [
    "# Лабораторная работа №4 \"Проведение исследований со случайным лесом\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06ae7dd",
   "metadata": {},
   "source": [
    "### Ход работы"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91f4191",
   "metadata": {},
   "source": [
    "Импортируем библиотеки перед работой"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e967b4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV, train_test_split, KFold, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.metrics import accuracy_score, classification_report, mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from scipy.stats import randint\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from sklearn.tree import DecisionTreeClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8114e9",
   "metadata": {},
   "source": [
    "##### Создание бейзлайна для модели классификации"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc586b35",
   "metadata": {},
   "source": [
    "Проведём те же манипуляции, что и ранне: выгрузим датасет и минимально его обработаем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e9761dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_base_df = pd.read_csv(\"../classification.csv\").sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "c_base_df = c_base_df.drop(columns=['instance_id', 'obtained_date', 'track_name', 'artist_name'])\n",
    "\n",
    "c_base_df.drop_duplicates()\n",
    "\n",
    "c_base_df['tempo'] = pd.to_numeric(c_base_df['tempo'], errors='coerce')\n",
    "\n",
    "le = LabelEncoder()\n",
    "c_base_df['mode'] = le.fit_transform(c_base_df['mode'])\n",
    "c_base_df['music_genre'] = le.fit_transform(c_base_df['music_genre'])\n",
    "c_base_df['key'] = le.fit_transform(c_base_df['key'])\n",
    "\n",
    "median_tempo = c_base_df['tempo'].median()\n",
    "c_base_df['tempo'] = c_base_df['tempo'].fillna(median_tempo)\n",
    "\n",
    "X_c_base = c_base_df.drop(columns=[\"music_genre\"])\n",
    "y_c_base = c_base_df[\"music_genre\"]\n",
    "\n",
    "X_c_base_train, X_c_base_test, y_c_base_train, y_c_base_test = train_test_split(\n",
    "    X_c_base,\n",
    "    y_c_base,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y_c_base\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f601b6bb",
   "metadata": {},
   "source": [
    "Теперь обучим модель из sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "066d24ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4723\n"
     ]
    }
   ],
   "source": [
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=100, \n",
    "    random_state=42,\n",
    "    max_depth=3\n",
    ")\n",
    "\n",
    "rf_model.fit(X_c_base_train, y_c_base_train)\n",
    "\n",
    "y_pred = rf_model.predict(X_c_base_test)\n",
    "\n",
    "accuracy = accuracy_score(y_c_base_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba70947",
   "metadata": {},
   "source": [
    "##### Улучшение бейзлайна для модели классификации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e27b982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.01      0.02      1000\n",
      "           1       0.56      0.64      0.60      1000\n",
      "           2       0.38      0.34      0.36      1000\n",
      "           3       0.68      0.85      0.76      1000\n",
      "           4       0.61      0.41      0.49      1000\n",
      "           5       0.41      0.61      0.49      1000\n",
      "           6       0.45      0.73      0.55      1000\n",
      "           7       0.46      0.09      0.15      1000\n",
      "           8       0.39      0.17      0.24      1000\n",
      "           9       0.38      0.86      0.53      1000\n",
      "\n",
      "    accuracy                           0.47     10000\n",
      "   macro avg       0.49      0.47      0.42     10000\n",
      "weighted avg       0.49      0.47      0.42     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_c_base_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1b2059",
   "metadata": {},
   "source": [
    "Это лучше чем одно решающее дерево. Теперь преобразуем датасет как ранее"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "89a69a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_df = pd.read_csv(\"../classification.csv\").sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "c_df = c_df.drop(columns=['instance_id', 'obtained_date', 'track_name', 'artist_name'])\n",
    "\n",
    "\n",
    "sc = StandardScaler()\n",
    "scaled = sc.fit_transform(c_df[['loudness', 'acousticness', 'energy']]) # ранее я не замечал, что loudness просто съедала остальные фичи \n",
    "pca = PCA(n_components=2)\n",
    "c_df[['pc1', 'pc2']] = pca.fit_transform(scaled)\n",
    "c_df = c_df.drop(columns=['loudness', 'acousticness', 'energy'])\n",
    "\n",
    "c_df['tempo'] = pd.to_numeric(c_df['tempo'], errors='coerce')\n",
    "\n",
    "le = LabelEncoder()\n",
    "c_df['music_genre'] = le.fit_transform(c_df['music_genre'])\n",
    "c_df['mode'] = le.fit_transform(c_df['mode'])\n",
    "\n",
    "ohe = OneHotEncoder(sparse_output=False, drop='first')\n",
    "encoded_key = ohe.fit_transform(c_df[['key']])\n",
    "encoded_df_key = pd.DataFrame(encoded_key, columns=ohe.get_feature_names_out(['key']))\n",
    "c_df = c_df.drop(columns=['key']).reset_index(drop=True)\n",
    "c_df = pd.concat([c_df, encoded_df_key], axis=1)\n",
    "\n",
    "c_df['duration_ms'] = c_df['duration_ms'].replace(-1, np.nan)\n",
    "\n",
    "c_df['instrumental_flag'] = (c_df['instrumentalness'] > 0.05).astype(int)\n",
    "c_df = c_df.drop(columns=['instrumentalness'])\n",
    "\n",
    "c_df['undefined_tempo'] = c_df['tempo'].isna().astype(int)\n",
    "\n",
    "median_tempo = c_df['tempo'].median()\n",
    "c_df['tempo'] = c_df['tempo'].fillna(median_tempo)\n",
    "\n",
    "median_duration = c_df['duration_ms'].median()\n",
    "c_df['duration_ms'] = c_df['duration_ms'].fillna(median_duration)\n",
    "\n",
    "float_features = [\n",
    "    'popularity', 'danceability', 'duration_ms',\n",
    "    'liveness', 'speechiness', 'tempo',\n",
    "    'valence', 'pc1', 'pc2'\n",
    "]\n",
    "\n",
    "other_features = [\n",
    "    'mode', 'instrumental_flag', 'undefined_tempo'\n",
    "] + list(encoded_df_key.columns) \n",
    "\n",
    "X_c = c_df[float_features + other_features]\n",
    "y_c = c_df['music_genre']\n",
    "\n",
    "X_c_train, X_c_test, y_c_train, y_c_test = train_test_split(\n",
    "    X_c, y_c, test_size=0.2, stratify=y_c, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca6dd03",
   "metadata": {},
   "source": [
    "Перейдём к обучению"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a925cc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "Best params: {'n_estimators': 200, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'max_depth': 20}\n",
      "Score: 0.543\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.32      0.38      1000\n",
      "           1       0.77      0.74      0.75      1000\n",
      "           2       0.59      0.51      0.54      1000\n",
      "           3       0.82      0.83      0.83      1000\n",
      "           4       0.56      0.57      0.56      1000\n",
      "           5       0.62      0.60      0.61      1000\n",
      "           6       0.34      0.38      0.36      1000\n",
      "           7       0.53      0.50      0.51      1000\n",
      "           8       0.30      0.28      0.29      1000\n",
      "           9       0.48      0.70      0.57      1000\n",
      "\n",
      "    accuracy                           0.54     10000\n",
      "   macro avg       0.55      0.54      0.54     10000\n",
      "weighted avg       0.55      0.54      0.54     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(\n",
    "    random_state=42,\n",
    "    n_jobs=1\n",
    ")\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [None, 5, 10, 20],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2],\n",
    "    'max_features': ['sqrt', 'log2']\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "grid_search = RandomizedSearchCV(\n",
    "    estimator=rf,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=30,\n",
    "    scoring='accuracy',\n",
    "    cv=cv,\n",
    "    n_jobs=1,  \n",
    "    verbose=1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "grid_search.fit(X_c_train, y_c_train)\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "print(\"Best params:\", grid_search.best_params_)\n",
    "\n",
    "y_pred = best_model.predict(X_c_test)\n",
    "\n",
    "print(\"Score:\", accuracy_score(y_c_test, y_pred))\n",
    "\n",
    "print(classification_report(y_c_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56013d9a",
   "metadata": {},
   "source": [
    "##### Создание бейзлайна для модели регрессии"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97aae698",
   "metadata": {},
   "source": [
    "Сделаем всё то же, что и ранее"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f19bdf32",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_base_df = pd.read_csv(\"../regression.csv\").sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "r_base_df['Date'] = pd.to_datetime(r_base_df['Date'], dayfirst=True)\n",
    "\n",
    "r_base_df[\"Year\"] = r_base_df[\"Date\"].dt.year\n",
    "r_base_df[\"Month\"] = r_base_df[\"Date\"].dt.month\n",
    "r_base_df[\"Day\"] = r_base_df[\"Date\"].dt.day\n",
    "\n",
    "r_base_df = r_base_df.drop(columns=['Date'])\n",
    "\n",
    "per_store_count = r_base_df.groupby('Store').size().iloc[0]\n",
    "k = max(1, int(np.round(0.8 * per_store_count))) \n",
    "store_counts = r_base_df['Store'].nunique()\n",
    "\n",
    "train = r_base_df.iloc[: store_counts * k]\n",
    "test = r_base_df.iloc[store_counts * k :]\n",
    "\n",
    "X_r_base_train = train.drop(columns=['Weekly_Sales'])\n",
    "X_r_base_test = test.drop(columns=['Weekly_Sales'])\n",
    "y_r_base_train = train['Weekly_Sales']\n",
    "y_r_base_test = test['Weekly_Sales']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ecea8e1",
   "metadata": {},
   "source": [
    "И теперь обучим модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "99a7fa3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 329429.9998288926\n",
      "RMSE: 432505.5663012246\n",
      "R2: 0.42180745594044\n"
     ]
    }
   ],
   "source": [
    "rf_regressor = RandomForestRegressor(\n",
    "    n_estimators=100, \n",
    "    random_state=42,\n",
    "    max_depth=3\n",
    ")\n",
    "\n",
    "rf_regressor.fit(X_r_base_train, y_r_base_train)\n",
    "\n",
    "y_pred = rf_regressor.predict(X_r_base_test)\n",
    "\n",
    "mae = mean_absolute_error(y_r_base_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_r_base_test, y_pred))\n",
    "r2 = r2_score(y_r_base_test, y_pred)\n",
    "\n",
    "print(\"MAE:\", mae)\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"R2:\", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9286239c",
   "metadata": {},
   "source": [
    "##### Улучшение бейзлайна для модели регрессии"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c23df1a",
   "metadata": {},
   "source": [
    "Сначала повторим техники из предыдущей ЛР"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c6643831",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_df = pd.read_csv(\"../regression.csv\").sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "r_df['Date'] = pd.to_datetime(r_df['Date'], dayfirst=True)\n",
    "\n",
    "r_df['Year'] = r_df['Date'].dt.year\n",
    "r_df['Week'] = r_df['Date'].dt.isocalendar().week\n",
    "\n",
    "r_df = r_df.drop(columns=['Date'])\n",
    "\n",
    "cat_store = ['Store', 'Week']\n",
    "other_feats = ['Temperature', 'Fuel_Price', 'CPI', 'Unemployment', 'Year', 'Holiday_Flag']\n",
    "\n",
    "per_store_count = r_df.groupby('Store').size().iloc[0]\n",
    "k = max(1, int(np.round(0.8 * per_store_count))) \n",
    "store_counts = r_df['Store'].nunique()\n",
    "\n",
    "train = r_df.iloc[: store_counts * k]\n",
    "test = r_df.iloc[store_counts * k :]\n",
    "\n",
    "X_r_train = train.drop(columns=['Weekly_Sales'])\n",
    "X_r_test = test.drop(columns=['Weekly_Sales'])\n",
    "y_r_train = train['Weekly_Sales']\n",
    "y_r_test = test['Weekly_Sales']\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('ohe', OneHotEncoder(handle_unknown='ignore', sparse_output=False), cat_store),\n",
    "        ('passth', 'passthrough', other_feats)\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7baf8ee4",
   "metadata": {},
   "source": [
    "Перейдём к обучению"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a320e6fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 120 candidates, totalling 600 fits\n",
      "Best params: {'rf__max_depth': None, 'rf__max_features': 'sqrt', 'rf__min_samples_leaf': 1, 'rf__min_samples_split': 2, 'rf__n_estimators': 300}\n",
      "MAE: 63864.84128812266\n",
      "RMSE: 120223.71316758188\n",
      "R2: 0.9553245064363924\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('rf', RandomForestRegressor(random_state=42))\n",
    "])\n",
    "\n",
    "param_dist = {\n",
    "    'rf__n_estimators': [100, 200, 300],\n",
    "    'rf__max_depth': [None, 5, 10, 15, 20],\n",
    "    'rf__min_samples_split': [2, 5],\n",
    "    'rf__min_samples_leaf': [1, 2],\n",
    "    'rf__max_features': ['sqrt', 'log2']\n",
    "}\n",
    "\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_grid=param_dist,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    cv=cv,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_r_train, y_r_train)\n",
    "\n",
    "print(\"Best params:\", grid_search.best_params_)\n",
    "best_model = grid_search.best_estimator_\n",
    "y_test_pred  = best_model.predict(X_r_test)\n",
    "\n",
    "mae = mean_absolute_error(y_r_test, y_test_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_r_test, y_test_pred))\n",
    "r2 = r2_score(y_r_test, y_test_pred)\n",
    "\n",
    "print(\"MAE:\", mae)\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"R2:\", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda2216d",
   "metadata": {},
   "source": [
    "##### Базовый класс имплементации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8454f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseRandomForest:\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_estimators=100,\n",
    "        min_samples_split=2,\n",
    "        min_samples_leaf=1,\n",
    "        max_features=\"sqrt\",\n",
    "        max_depth=None,\n",
    "    ):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "        self.max_features = max_features\n",
    "        self.max_depth = max_depth\n",
    "        self.trees_ = []\n",
    "\n",
    "    def _create_tree(self):\n",
    "        \"\"\"Создание одного дерева (Classifier или Regressor).\"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def _aggregate_predictions(self, predictions):\n",
    "        \"\"\"Агрегация предсказаний деревьев.\"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def _bootstrap_sample(self, X, y):\n",
    "        \"\"\"\n",
    "        Bootstrap-сэмплирование.\n",
    "        \"\"\"\n",
    "        n_samples = X.shape[0]\n",
    "        indices = np.random.randint(0, n_samples, n_samples)\n",
    "\n",
    "        # pandas\n",
    "        if hasattr(X, \"iloc\"):\n",
    "            return X.iloc[indices], y.iloc[indices]\n",
    "\n",
    "        # numpy\n",
    "        return X[indices], y[indices]\n",
    "\n",
    "    def _fit_single_tree(self, X, y):\n",
    "        \"\"\"\n",
    "        Обучение одного дерева.\n",
    "        \"\"\"\n",
    "        # Bootstrap\n",
    "        X_sample, y_sample = self._bootstrap_sample(X, y)\n",
    "\n",
    "        # Создание дерева\n",
    "        tree = self._create_tree()\n",
    "\n",
    "        # Обучение дерева\n",
    "        tree.fit(X_sample, y_sample)\n",
    "        return tree\n",
    "\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Обучение случайного леса (последовательно).\n",
    "        \"\"\"\n",
    "        self.trees_ = []\n",
    "\n",
    "        for _ in range(self.n_estimators):\n",
    "            tree = self._fit_single_tree(X, y)\n",
    "            self.trees_.append(tree)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Предсказание леса.\n",
    "        \"\"\"\n",
    "        predictions = np.asarray([tree.predict(X) for tree in self.trees_])\n",
    "        return self._aggregate_predictions(predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6ef4c9",
   "metadata": {},
   "source": [
    "##### Классификатор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b7268d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyRandomForestClassifier(BaseRandomForest):\n",
    "\n",
    "    def _create_tree(self):\n",
    "        \"\"\"\n",
    "        Создание одного дерева классификации.\n",
    "        Все гиперпараметры прокидываются из леса.\n",
    "        Здесь и далее будут использоваться деревья из sklearn для экономии времени\n",
    "        и более честного сравнения самого алгоритма\n",
    "        \"\"\"\n",
    "        return DecisionTreeClassifier(\n",
    "            min_samples_split=self.min_samples_split,\n",
    "            min_samples_leaf=self.min_samples_leaf,\n",
    "            max_features=self.max_features,\n",
    "            max_depth=self.max_depth,\n",
    "        )\n",
    "\n",
    "    def _aggregate_predictions(self, predictions):\n",
    "        \"\"\"\n",
    "        Агрегация предсказаний деревьев.\n",
    "        Используется голосование большинством.\n",
    "        \"\"\"\n",
    "        n_samples = predictions.shape[1]\n",
    "        y_pred = np.empty(n_samples, dtype=predictions.dtype)\n",
    "\n",
    "        # Голосование по каждому объекту\n",
    "        for i in range(n_samples):\n",
    "            values, counts = np.unique(predictions[:, i], return_counts=True)\n",
    "            y_pred[i] = values[np.argmax(counts)]\n",
    "\n",
    "        return y_pred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5cb81b",
   "metadata": {},
   "source": [
    "Обучим на данных бейзлайна"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1400e52c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4179\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      1000\n",
      "           1       0.71      0.14      0.23      1000\n",
      "           2       0.42      0.26      0.32      1000\n",
      "           3       0.71      0.83      0.76      1000\n",
      "           4       0.32      0.55      0.40      1000\n",
      "           5       0.36      0.71      0.48      1000\n",
      "           6       0.38      0.89      0.53      1000\n",
      "           7       0.38      0.03      0.05      1000\n",
      "           8       0.00      0.00      0.00      1000\n",
      "           9       0.40      0.78      0.53      1000\n",
      "\n",
      "    accuracy                           0.42     10000\n",
      "   macro avg       0.37      0.42      0.33     10000\n",
      "weighted avg       0.37      0.42      0.33     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_model = MyRandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=3\n",
    ")\n",
    "\n",
    "rf_model.fit(X_c_base_train, y_c_base_train)\n",
    "\n",
    "y_pred = rf_model.predict(X_c_base_test)\n",
    "\n",
    "accuracy = accuracy_score(y_c_base_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(classification_report(y_c_base_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43ef53d",
   "metadata": {},
   "source": [
    "Обучим на данных улучшенной модели. Сразу будем использовать параметры, полученные при подборе гиперпараметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e7782ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.5437\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.38      0.39      1000\n",
      "           1       0.75      0.75      0.75      1000\n",
      "           2       0.57      0.53      0.55      1000\n",
      "           3       0.83      0.83      0.83      1000\n",
      "           4       0.57      0.56      0.56      1000\n",
      "           5       0.63      0.60      0.62      1000\n",
      "           6       0.36      0.47      0.40      1000\n",
      "           7       0.57      0.46      0.51      1000\n",
      "           8       0.28      0.20      0.23      1000\n",
      "           9       0.48      0.66      0.56      1000\n",
      "\n",
      "    accuracy                           0.54     10000\n",
      "   macro avg       0.54      0.54      0.54     10000\n",
      "weighted avg       0.54      0.54      0.54     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_model = MyRandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=20,\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=2\n",
    ")\n",
    "\n",
    "rf_model.fit(X_c_train, y_c_train)\n",
    "\n",
    "y_pred = rf_model.predict(X_c_test)\n",
    "\n",
    "print(\"Score:\", accuracy_score(y_c_test, y_pred))\n",
    "\n",
    "print(classification_report(y_c_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67a8f7f",
   "metadata": {},
   "source": [
    "Имеем скоры:\n",
    "\n",
    "**Бейзлайн sklearn** - 0.4723\n",
    "\n",
    "**Улучшенная модель sklearn** - 0.543\n",
    "\n",
    "**Мой бейзлайн** - 0.4179\n",
    "\n",
    "**Мой улучшенный бейзлайн** - 0.5437\n",
    "\n",
    "Моя модель не отличается по скору от модели sklearn на улучшенных версиях"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4237e1cb",
   "metadata": {},
   "source": [
    "##### Регрессор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ddaea9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "\n",
    "class MyRandomForestRegressor(BaseRandomForest):\n",
    "    \"\"\"\n",
    "    Случайный лес для регрессии.\n",
    "\n",
    "    Наследуется от BaseRandomForest и реализует:\n",
    "    - создание регрессионного дерева\n",
    "    - агрегацию предсказаний усреднением\n",
    "    \"\"\"\n",
    "\n",
    "    def _create_tree(self):\n",
    "        \"\"\"\n",
    "        Создание одного дерева регрессии.\n",
    "        \"\"\"\n",
    "        return DecisionTreeRegressor(\n",
    "            min_samples_split=self.min_samples_split,\n",
    "            min_samples_leaf=self.min_samples_leaf,\n",
    "            max_features=self.max_features,\n",
    "            max_depth=self.max_depth,\n",
    "        )\n",
    "\n",
    "    def _aggregate_predictions(self, predictions):\n",
    "        \"\"\"\n",
    "        Агрегация предсказаний деревьев.\n",
    "\n",
    "        predictions shape:\n",
    "        (n_estimators, n_samples)\n",
    "\n",
    "        Для регрессии используется усреднение.\n",
    "        \"\"\"\n",
    "        return predictions.mean(axis=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ae51ad",
   "metadata": {},
   "source": [
    "Обучим на данных бейзлайна"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "15235eb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 390951.74828000314\n",
      "RMSE: 471079.7424955274\n",
      "R2: 0.31407292980488344\n"
     ]
    }
   ],
   "source": [
    "rf_regressor = MyRandomForestRegressor(\n",
    "    n_estimators=100, \n",
    "    max_depth=3\n",
    ")\n",
    "\n",
    "rf_regressor.fit(X_r_base_train, y_r_base_train)\n",
    "\n",
    "y_pred = rf_regressor.predict(X_r_base_test)\n",
    "\n",
    "mae = mean_absolute_error(y_r_base_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_r_base_test, y_pred))\n",
    "r2 = r2_score(y_r_base_test, y_pred)\n",
    "\n",
    "print(\"MAE:\", mae)\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"R2:\", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53f85c5",
   "metadata": {},
   "source": [
    "Обучим на данных улучшенной модели. Сразу будем использовать параметры, полученные при подборе гиперпараметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "29c03924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 64193.45753407412\n",
      "RMSE: 120375.05403558185\n",
      "R2: 0.9552119581977049\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('rf', MyRandomForestRegressor(min_samples_leaf=1, min_samples_split=2, n_estimators=300))\n",
    "])\n",
    "\n",
    "pipeline.fit(X_r_train, y_r_train)\n",
    "\n",
    "y_test_pred  = pipeline.predict(X_r_test)\n",
    "\n",
    "mae = mean_absolute_error(y_r_test, y_test_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_r_test, y_test_pred))\n",
    "r2 = r2_score(y_r_test, y_test_pred)\n",
    "\n",
    "print(\"MAE:\", mae)\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"R2:\", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978db054",
   "metadata": {},
   "source": [
    "Получили\n",
    "\n",
    "| Метрика | Бейзлайн случайного леса | Бейзлайн имплементации | Улучшенный случайный лес | Улучшенная имплементация |\n",
    "|-|-|-|-|-|\n",
    "| MAE | 329430 | 390952 | 63865 | 64193 |\n",
    "| RMSE | 432506 | 471080 | 120224 | 120375 |\n",
    "| R2 | 0.421 | 0.314 | 0.955 | 0.955 |\n",
    "\n",
    "Практически одинаковые метрики на улучшенных версиях"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
